<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Student Counter</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <style>
        body { text-align: center; font-family: Arial, sans-serif; }
        video, canvas { width: 80%; max-width: 600px; display: block; margin: auto; }
        #count { font-weight: bold; color: green; }
        button { margin-top: 10px; padding: 10px 20px; font-size: 16px; }
    </style>
</head>
<body>
    <h1>Students in Class: <span id="count">0</span></h1>
    <video id="video" autoplay playsinline></video>
    <canvas id="canvas"></canvas>
    <button id="switch-camera">Switch Camera</button>

    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const countDisplay = document.getElementById('count');
        const switchCameraButton = document.getElementById('switch-camera');

        let currentFacingMode = 'environment'; // Default to back camera

        async function setupCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode: { ideal: currentFacingMode } }
                });
                video.srcObject = stream;
                return new Promise(resolve => video.onloadedmetadata = resolve);
            } catch (error) {
                alert('Camera access error: ' + error.message);
            }
        }

        async function detectPeople() {
            const cocoModel = await cocoSsd.load();
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;

            async function detect() {
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                const predictions = await cocoModel.detect(canvas);
                const people = predictions.filter(p => p.class === 'person');
                countDisplay.textContent = people.length;
                requestAnimationFrame(detect); // Continuous detection
            }

            detect();
        }

        switchCameraButton.addEventListener('click', async () => {
            currentFacingMode = currentFacingMode === 'environment' ? 'user' : 'environment';
            await setupCamera(); // Restart camera with new facing mode
        });

        setupCamera().then(detectPeople);
    </script>
</body>
</html>
